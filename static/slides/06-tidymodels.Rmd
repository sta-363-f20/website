---
title: "tidymodels"
author: "Dr. D'Agostino McGowan"
output:
  xaringan::moon_reader:
    css: "slides.css"
    logo: img/icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---



```{r child = "setup.Rmd"}
```

layout: true

<div class="my-footer">
<span>
Dr. Lucy D'Agostino McGowan <i> adapted from Alison Hill's Introduction to ML with the Tidyverse</i>
</span>
</div> 

```{r, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(tidymodels)
library(broom)
library(ISLR)
library(countdown)
```

---

## tidymodels

.pull-left[
![](img/02/tidymodels.png)
]

.pull-right[
.center[
[tidymodels.org](https://www.tidymodels.org/)
]

- tidymodels is an opinionated collection of R packages designed for modeling and statistical analysis.
- All packages share an underlying philosophy and a common grammar.
]

---

## Step 1: Specify the model

* Pick the **model**
--

* Set the **engine**

---

## Specify the model


```{r, eval = FALSE}
linear_reg() %>%
  set_engine("lm")
```

---

## Specify the model


```{r, eval = FALSE}
linear_reg() %>%
  set_engine("glmnet")
```

---

## Specify the model


```{r, eval = FALSE}
linear_reg() %>%
  set_engine("spark")
```

---

## Specify the model


```{r, eval = FALSE}
decision_tree() %>%
  set_engine("ranger")
```

---

## Specify the model

* All available models:

https://www.tidymodels.org

---

class: inverse

## `r fontawesome::fa("laptop")` `Specify Model`

Write a pipe that creates a model that uses `lm()` to fit a linear regression using tidymodels. Save it as `lm_spec` and look at the object. What does it return?

_Hint: you'll need  https://www.tidymodels.org_

`r countdown::countdown(minutes = 2)`

---

```{r}
lm_spec <- 
  linear_reg() %>% # Pick linear regression
  set_engine(engine = "lm") # set engine
lm_spec
```

---

## Fit the data

* You can train your model using the `fit()` function

```{r}
fit(lm_spec,
    mpg ~ horsepower,
    data = Auto)
```

---

class: inverse

## `r fontawesome::fa("laptop")` `Fit Model`

Fit the model:

```{r, eval = FALSE}
library(ISLR)
lm_fit <- fit(lm_spec,
              mpg ~ horsepower,
              data = Auto)
lm_fit
```

Does this give the same results as

```{r, eval = FALSE}
lm(mpg ~ horsepower, data = Auto)
```

`r countdown::countdown(1, 30)`

---

```{r, echo = FALSE}
lm_fit <- fit(lm_spec,
              mpg ~ horsepower,
              data = Auto)
```


## Get predictions

```{r, eval = FALSE}
lm_fit %>%
  predict(new_data = Auto)
```

--

* Uses the `predict()` function
--

* `r emo::ji("double_exclamation_mark")` `new_data` has an underscore
--

* `r emo::ji("smile")` This automagically creates a data frame

---

## Get predictions

```{r}
lm_fit %>%
  predict(new_data = Auto) %>%
  bind_cols(Auto)
```

---

class: inverse

`r countdown::countdown(minutes = 1, 30)`

## `r fontawesome::fa("laptop")` `Get predictions`

Edit the code below to add the original data to the predicted data.


```{r, eval = FALSE}
mpg_pred <- lm_fit %>% 
  predict(new_data = Auto) %>% 
  ---
```

---

## Get predictions

```{r}
mpg_pred <- lm_fit %>%
  predict(new_data = Auto) %>%
  bind_cols(Auto)

mpg_pred
```

---

## Calculate the error

* Root mean square error

```{r}
mpg_pred %>%
  rmse(truth = mpg, estimate = .pred)
```

--

.question[
What is this estimate? (training error? testing error?)
]

---

## Validation set approach

```{r}
Auto_split <- initial_split(Auto, prop = 0.5)
Auto_split
```

--

* Extract the training and testing data

```{r, eval = FALSE}
training(Auto_split)
testing(Auto_split)
```

---

## Validation set approach

```{r}
Auto_train <- training(Auto_split)
```

```{r, eval = FALSE}
Auto_train
```

.small[
```{r, echo = FALSE}
as_tibble(Auto_train)
```
]


---

class: inverse

`r countdown::countdown(minutes = 4)`

## `r fontawesome::fa("laptop")` `Validation Set`

Copy the code below, fill in the blanks to fit a model on the **training** data then calculate the **test** RMSE.

```{r, eval = FALSE}
set.seed(100)
Auto_split  <- ________
Auto_train  <- ________
Auto_test   <- ________
lm_fit      <- fit(lm_spec, 
                   mpg ~ horsepower, 
                   data = ________)
mpg_pred  <- ________ %>% 
  predict(new_data = ________) %>% 
  bind_cols(________)
rmse(________, truth = ________, estimate = ________)
```

---

## A faster way!

* You can use `last_fit()` and specify the split
* This will automatically train the data on the `train` data from the split
* Instead of specifying which metric to calculate (with `rmse` as before) you can just use `collect_metrics()` and it will automatically calculate the metrics on the `test` data from the split

```{r}
set.seed(100)

Auto_split <- initial_split(Auto, prop = 0.5)
lm_fit <- last_fit(lm_spec,
                   mpg ~ horsepower,
                   split = Auto_split) #<<

lm_fit %>%
  collect_metrics() #<<
```

---

## What about cross validation?

```{r}
Auto_cv <- vfold_cv(Auto, v = 5)
Auto_cv
```

---

## What about cross validation?

--

```{r, eval = FALSE}
fit_resamples(lm_spec, #<<
              mpg ~ horsepower,
              resamples = Auto_cv) #<<
```

---

## What about cross validation?

```{r}
fit_resamples(lm_spec,
              mpg ~ horsepower,
              resamples = Auto_cv)
```

---

## What about cross validation?

.question[
How do we get the metrics out? With `collect_metrics()` again!
]

--

```{r}
results <- fit_resamples(lm_spec,
                         mpg ~ horsepower,
                         resamples = Auto_cv)

results %>%
  collect_metrics()
```

---


class: inverse

`r countdown::countdown(minutes = 2)`

## `r fontawesome::fa("laptop")` `K-fold cross validation`


Edit the code below to get the 5-fold cross validation error rate for the following model:

$mpg = \beta_0 + \beta_1 horsepower + \beta_2 horsepower^2+ \epsilon$

```{r, eval = FALSE}
Auto_cv <- vfold_cv(Auto, v = 5)

results <- fit_resamples(lm_spec,
                         ----,
                         resamples = ---)

results %>%
  collect_metrics()
```

* What do you think `rsq` is?

---

